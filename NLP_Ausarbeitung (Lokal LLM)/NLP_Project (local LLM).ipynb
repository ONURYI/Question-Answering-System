{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NLP Praxis Projekt - Question Answering System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfReader\n",
    "import textwrap\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import pipeline\n",
    "\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from InstructorEmbedding import INSTRUCTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tokenizer und Modell**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die erste Zeile des Codes lädt einen Tokenizer mithilfe der AutoTokenizer.from_pretrained Methode. Der Tokenizer wird verwendet, um den Input-Text in Tokens zu zerlegen, die das Modell verstehen kann. In diesem Fall wird der Tokenizer für das Modell \"google/flan-t5-small\" geladen.\n",
    "\n",
    "Die zweite Zeile des Codes lädt ein vortrainiertes sequenz-zu-sequenz Modell (Seq2Seq) mit der AutoModelForSeq2SeqLM.from_pretrained Methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline für Text-zu-Text-Generierung erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.15\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF erfolgreich in Text konvertiert und in ../PDF and TXT Folder/accounts-payable.txt gespeichert.\n"
     ]
    }
   ],
   "source": [
    "def pdf_to_txt(pdf_path, txt_path):\n",
    "    try:\n",
    "        pdf_file = open(pdf_path, 'rb')\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "        pdf_text = \"\"\n",
    "\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            pdf_text += page.extract_text()\n",
    "\n",
    "        # Schließen Sie die PDF-Datei\n",
    "        pdf_file.close()\n",
    "\n",
    "        with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
    "            txt_file.write(pdf_text)\n",
    "\n",
    "        print(\"PDF erfolgreich in Text konvertiert und in {} gespeichert.\".format(txt_path))\n",
    "    except Exception as e:\n",
    "        print(\"Fehler beim Konvertieren der PDF in Text:\", str(e))\n",
    "\n",
    "\n",
    "pdf_path = '../PDF and TXT Folder/accounts-payable.pdf'\n",
    "txt_path = '../PDF and TXT Folder/accounts-payable.txt'\n",
    "pdf_to_txt(pdf_path, txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('../PDF and TXT Folder/accounts-payable.txt')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunks aufteilen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Instructor Emebeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(documents=texts, embedding=instructor_embeddings, persist_directory='../db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retriever -> 21x wird es durchgegangen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 21})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=local_llm, \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier ist der Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accounts payable (AP) is the department in a company that’s responsible for paying\n",
      "\n",
      "\n",
      "Sources:\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the Accounts Payable process?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accounts payable teams use the three-way match process to ensure that they only pay invoices\n",
      "\n",
      "\n",
      "Sources:\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n",
      "../PDF and TXT Folder/accounts-payable.txt\n"
     ]
    }
   ],
   "source": [
    "query2 = \"What is the three way match meaning?\"\n",
    "llm_response = qa_chain(query2)\n",
    "process_llm_response(llm_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
